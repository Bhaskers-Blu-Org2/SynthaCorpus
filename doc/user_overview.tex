\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{listings}

\newcommand{\red}[1]{{\color{red}{\emph{#1}}}}
\newcommand{\projectName}{\texttt{SynthaCorpus}}

\title{User Overview of \projectName}
\author{Microsoft}

\begin{document}
\maketitle{}


In its simplest form a text corpus consists of a set of documents,
each containing text, comprising a sequence of words\footnote{In CJKT
  languages, such as Chinese, there is no explicit segmentation into
  words. \projectName~ doesn't yet attempt to deal with CJKT text.}.
A synthetic corpus has the same form, but the sequence of words in a
document may be randomly chosen, and the representation of the words
may be made up.

Like real corpora, synthetic corpora have observable properties such
as total number of word occurrences, vocabulary size, term frequency
distribution, document length distribution, letter frequency
distribution, word length distribution and so on.

Real corpora have other properties such as internal structure and
external linking which are not currently modelled by \projectName.

There are a number of scenarios in which \projectName~ may be useful:
\begin{enumerate}
  \item when you need to work with a private corpus you're
    not entitled to see,
  \item when someone wants to replicate results
    you obtained on a corpus you can't share  for reasons of
    confidentiality, or size,
  \item when you want to realistically scale up a corpus
  \item when you want to engineer an artificial corpus with 
    specific properties, e.g. to stress test an IR system,
\end{enumerate}

\section{Getting going with \projectName}

\subsection{Obtaining \projectName}

Assuming you are working with a Unix style shell, e.g. on Linux or MacOSx,
under Cygwin, or under Ubuntu Bash for Windows 10 ....

\begin{verbatim}
git clone "https://github.com/Microsoft/Synthacorpus"
\end{verbatim}


\subsection{Prerequisites}

To use the system you need to build executables from their sources.
For this you need to have installed either \texttt{gcc} and
\texttt{make} or Microsoft Visual Studio 2015.

To use the system you will also need to have \texttt{perl 5}
installed.  Finally, to generate PDF plots (optional) and view them you will
need to have installed the \texttt{gnuplot} package and a PDF viewer
such as \texttt{acrobat reader}, \texttt{okular}, \texttt{preview}, or
a browser such as \texttt{edge}.

\subsection{Building with gcc / make}

If you have \texttt{gcc}, \texttt{make}, \texttt{perl} and
\texttt{gnuplot} installed and in your path you can just type:

\begin{verbatim}
cd SynthaCorpus/src    # Change to the src directory of the cloned repository
perl exerciser.pl
\end{verbatim}

The Exerciser script builds the executables from scratch and then runs
most of the tools, starting with a corpus derived from some Project
Gutenberg books.

\subsection{Building with Visual Studio 2015}

To build the executable using Visual Studio 2015 (VS 2015), please navigate to
\texttt{SynthaCorpus/src/Buildexes} using the file explorer, then
double click on \texttt{BuildAllExes.sln}. That should open the VS
2015 application.  In the lower part of the toolbar at the top
of the VS window, select \texttt{Release} and \texttt{x64} from the
first and second drop-downs.  Then click on \texttt{Rebuild solution}
from the \texttt{Build} menu.

If the build succeeds you should see
\begin{verbatim}
========== Rebuild All: 8 succeeded, 0 failed, 0 skipped ==========
\end{verbatim}
in the output pane at the bottom, and all eight exes will be in:

\begin{verbatim}
SynthaCorpus/src/BuildAllExes/x64/Release/
\end{verbatim}

You can then run the Exerciser script:
\begin{verbatim}
cd SynthaCorpus/src    # Change to the src directory of the cloned repository
perl exerciser.pl useVS   # An option containing VS removes any GCC
                          # exes and uses VS ones
\end{verbatim}



\section{Other documentation}
A companion document \url{developer_overview.pdf} gives more detail on 
uilding and using the system.  It also provides
information for developers who wish to understand how things work, or
to contribute enhancements or extensions to the project.  That
document lists some useful extensions which contributors may wish to
work on.

A set of HOWTOs in this directory is planned to  provide detailed
information on each of the main components of the system.  Currently
only \url{how_to_synthesize_a_corpus.pdf} which describes
\verb|corpusGenerator.exe| has been written.

The mathematics and science behind synthesizing a corpus with
specified properties is \red{described
  elsewhere}.


\section{Tools provided}

At the most fundamental level, the \projectName~ project provides executables for:
\begin{enumerate}
\item Extracting the properties of a text corpus. (\texttt{corpusPropertyExtractor.exe})
\item Generating a synthetic corpus with specified properties. (\texttt{corpusGenerator.exe})
\item Generating a set of known item queries from a text corpus. (\texttt{queryGenerator.exe})
\item Converting a query log for a base text corpus into a 
  version suitable for running against an emulation of the base. (\texttt{queryLogEmulator.exe})
\end{enumerate}

It also provides perl scripts to achieve:
\begin{description}
\item [Emulation of a corpus.] i.e. Extract the properties of a base
  corpus, then use the extracted properties to generate a mimic corpus.
  (\texttt{emulateARealCorpus.pl})
\item [Corpus sampling]. i.e. taking samples of a base corpus and
  extracting their properties.  Sample sizes range from 1\% to 100\%.
  Plotfiles are generated showing how the properties change with
  increasing sample size.  A growth model is also generated, allowing
  for potential scaling up.  The script also allows for temporal growth
  scenarios. (\texttt{samplingExperiments.pl})
\item [Scaling up a corpus]. i.e. generating a corpus many times
  larger than a real one, which has properties which might be expected
  of a larger version of the real corpus. (\texttt{scaleUpASample.pl})
\end{description}


\section{Corpus formats}
Currently the executables and scripts described above expect text to
be encoded in UTF-8 and stored in a single file recorded in one or
other of only two formats:
\begin{description}
  \item[TSV] Each document (with TABs and newlines removed) is
    represented by a single record.  The text of the document is in
    column 1, and a (numeric) static score is expected to be in column
    2. Other columns of metadata may optionally be present.
  \item[STARC] Simple Text Archive format allows documents to contain
    control characters, by prepending each record with an
    ASCII-encoded length.  The STARC format is specified in the
    Developer Overview.
\end{description}



\section{Limitations on size}
The size of corpus which can be generated, or whose properties can be
extracted, is limited by the amount of RAM you have.   Hash tables to
record all the n-grams in a corpus tend to be very large, and the programs in
\projectName~ are written to favour simplicity of coding at the expense of
memory demands.  Start with small corpora as in the example in the
next section, and gradually work up.  If your RAM is insufficient your
CPU utilisation percentage will eventually drop, and progress may slow
dramatically.


\section{Example usage}

Below are sequences of commands (similar to part of the content of the
\texttt{exerciser.pl} script) which create a STARC file from the Project Gutenberg documents,
emulates it, generates sets of known item queries for the base corpus
and also the emulated one, runs sampling experiments on the base
corpus, scales up a 1\% sample and compares the scaled-up sample with
the original.   The first version uses the executables built by
\texttt{gcc} and the second those built by Visual Studio 2015.

See the exerciser script for more examples of usage.
 
\subsection{GCC example}

{\footnotesize
\begin{verbatim}
cd SynthaCorpus/src
mkdir ../Experiments
./convertPGtoSTARC.exe ../ProjectGutenberg/*.txt > ../Experiments/PG.STARC
./emulateARealCorpus.pl PG Piecewise markov-5e dlhisto ngrams3
./queryGenerator.exe corpusFileName=../Experiments/PG.STARC 
    propertiesStem=../Experiments/Base/PG  -numQueries=1000
./queryGenerator.exe corpusFileName=../Experiments/Emulation/Piecewise/markov-5e_dlhisto_ngrams3/PG.starc 
    propertiesStem=../Experiments/Emulation/Piecewise/markov-5e_dlhisto_ngrams3/PG  -numQueries=1000
./samplingExperiments.pl PG
./scaleUpASample.pl PG 100 Linear markov-5e dlnormal ind
./queryGenerator.exe corpusFileName=../Experiments/Scalingup/Working/PG.tsv 
    propertiesStem=../Experiments/Scalingup/Working/PG  -numQueries=1000

\end{verbatim}
}
\subsection{VS 2015 example}

{\footnotesize
\begin{verbatim}
cd SynthaCorpus/src
mkdir ../Experiments
BuildAllExes/x64/Release/convertPGtoSTARC.exe ../ProjectGutenberg/*.txt > ../Experiments/PG.STARC
./emulateARealCorpus.pl PG Piecewise markov-5e dlhisto ngrams3
BuildAllExes/x64/Release/queryGenerator.exe corpusFileName=../Experiments/PG.STARC 
    propertiesStem=../Experiments/Base/PG  -numQueries=1000
BuildAllExes/x64/Release/queryGenerator.exe 
    corpusFileName=../Experiments/Emulation/Piecewise/markov-5e_dlhisto_ngrams3/PG.starc 
    propertiesStem=../Experiments/Emulation/Piecewise/markov-5e_dlhisto_ngrams3/PG  -numQueries=1000
./samplingExperiments.pl PG
./scaleUpASample.pl PG 100 Linear markov-5e dlnormal ind
BuildAllExes/x64/Release/queryGenerator.exe corpusFileName=../Experiments/Scalingup/Working/PG.tsv 
    propertiesStem=../Experiments/Scalingup/Working/PG  -numQueries=1000

\end{verbatim}
}
\end{document}
